{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import os\n",
    "import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "from tensorflow.keras.layers import  BatchNormalization, Conv2D, Dropout, MaxPooling2D ,Flatten, Dense\n",
    "from tensorflow.keras.layers import  Conv1D, MaxPooling1D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pd.read_csv('game.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_num = game.to_numpy()\n",
    "pre_num_contest = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_players(i):\n",
    "    players=[];\n",
    "    for j in range(5, 15):\n",
    "        players.append(game_num[i][j])\n",
    "    for j in range(20,30):\n",
    "        players.append(game_num[i][j])\n",
    "    date = game_num[i][1]\n",
    "    players=np.array(players)\n",
    "    return (players, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_data(player, date):\n",
    "    num_of_attribute = 23\n",
    "    name=player\n",
    "    X = []\n",
    "    none_player = np.ones((num_of_attribute));\n",
    "    if player=='none':\n",
    "        X.append(none_player)\n",
    "        X.append(none_player)\n",
    "        X.append(none_player)\n",
    "        return X\n",
    "    date_index = 1\n",
    "    \n",
    "    path = 'player2/'+player+'.csv'\n",
    "    player = pd.read_csv(path)\n",
    "    player_data = player.to_numpy()\n",
    "    \n",
    "    for i in range(0, len(player_data)):\n",
    "        if player_data[i][date_index]==date:\n",
    "            for k in range(1, pre_num_contest+1):\n",
    "                if(i-k>=0):\n",
    "                    X.append(player_data[i-k][date_index+1:])\n",
    "                else:\n",
    "                    X.append(none_player)\n",
    "            break\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_winner(i):\n",
    "    return game_num[i][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_game  = game_num.shape[0]\n",
    "total_num_of_player_in_one_game = 20\n",
    "X=[]\n",
    "Y = [];\n",
    "# for i in range(4, total_num_of_game):\n",
    "#     if(i%50==0):\n",
    "#         print(i)\n",
    "#     players=[]\n",
    "#     (players, date) = get_players(i)\n",
    "#     Y.append(get_winner(i))\n",
    "#     for j in range(0, total_num_of_player_in_one_game):\n",
    "#         if j==0:\n",
    "#             tmp = get_player_data(players[j], date);\n",
    "#         else:   \n",
    "#             test = (get_player_data(players[j], date))\n",
    "#             tmp = np.concatenate((tmp, test));\n",
    "        \n",
    "#     X.append(tmp);\n",
    "\n",
    "# X = np.array(X)\n",
    "# Y = np.array(Y)\n",
    "# print(X.shape)\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "# X = X.astype(float)\n",
    "\n",
    "# print(X.shape)\n",
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train = np.concatenate((X[:1000, :], X[1300:2300, :], X[2600:3600, :], X[3900:4900, :], X[5200:6200, :]), axis=0), np.concatenate((Y[:1000], Y[1300:2300], Y[2600:3600], Y[3900:4900], Y[5200:6200]), axis=0)\n",
    "# X_val, Y_val = np.concatenate((X[1000:1300, :], X[2300:2600, :], X[3600:3900, :], X[4900:5200, :], X[6200:, :]), axis=0), np.concatenate((Y[1000:1300], Y[2300:2600], Y[3600:3900], Y[4900:5200], Y[6200:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 60, 23, 1)\n",
      "(5000,)\n",
      "(1392, 60, 23, 1)\n",
      "(1392,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_train', X_train)\n",
    "# np.save('Y_train', Y_train)\n",
    "# np.save('X_val', X_val)\n",
    "# np.save('Y_val', Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(np.load('X_train.npy'), copy=True, nan=0.0)\n",
    "Y_train = np.load('Y_train.npy')\n",
    "X_val = np.nan_to_num(np.load('X_val.npy'), copy=True, nan=0.0)\n",
    "Y_val = np.load('Y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = utils.shuffle(X_train, Y_train)\n",
    "X_val, Y_val = utils.shuffle(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 60, 23, 1)\n",
      "(1392, 60, 23, 1)\n",
      "(5000, 1380)\n",
      "(1392, 1380)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "X_train = np.reshape(X_train, (5000, 60*23))\n",
    "X_val = np.reshape(X_val, (1392, 60*23))\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dan89\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5790229885057471"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(seed=84)\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "xgb_model.score(X_val, Y_val)\n",
    "# xgb_predict=xgb_model.predict(X_train)\n",
    "# xgb_predict_val=xgb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998563218390804"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(gamma='scale',probability=True)\n",
    "svm_model.fit(X_train, Y_train)\n",
    "svm_model.score(X_val, Y_val)\n",
    "# svm_predict=svm_model.predict(X_train)\n",
    "# svm_predict_val=svm_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 2 should be equal to 1380, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2484/4228794452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'autumn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mplot_svm_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2484/4228794452.py\u001b[0m in \u001b[0;36mplot_svm_decision_function\u001b[1;34m(model, ax, plot_support)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# plot decision boundary and margins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dan89\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0mof\u001b[0m \u001b[0movo\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \"\"\"\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ovr'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dan89\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;31m# NOTE: _validate_for_predict contains check for is_fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# hence must be placed before any other attributes are used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dan89\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    491\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[0;32m    494\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 2 should be equal to 1380, the number of features at training time"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_svm_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "plt.scatter(X_val[:, 0], X_val[:, 1], c=Y_val, s=50, cmap='autumn')\n",
    "plot_svm_decision_function(svm_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998563218390804"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDB_model = GradientBoostingClassifier(loss='deviance', \n",
    "                                       criterion='friedman_mse',\n",
    "                                       max_depth=4, \n",
    "                                       learning_rate=0.1, \n",
    "                                       max_features='sqrt')\n",
    "GDB_model.fit(X_train, Y_train)\n",
    "GDB_model.score(X_val, Y_val)\n",
    "# GDB_predict=GDB_model.predict(X_train)\n",
    "# GDB_predict_val=GDB_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6056034482758621"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "RF_model.fit(X_train, Y_train)\n",
    "RF_model.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict=np.reshape(xgb_predict, (5000,1))\n",
    "svm_predict=np.reshape(svm_predict, (5000,1))\n",
    "GDB_predict=np.reshape(GDB_predict, (5000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict_val=np.reshape(xgb_predict_val, (1392,1))\n",
    "svm_predict_val=np.reshape(svm_predict_val, (1392,1))\n",
    "GDB_predict_val=np.reshape(GDB_predict_val, (1392,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1392, 1)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDB_predict_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X=np.concatenate((xgb_predict,svm_predict,GDB_predict), axis=1)\n",
    "final_X_val=np.concatenate((xgb_predict_val,svm_predict_val,GDB_predict_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5790229885057471"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_final = SVC(gamma='scale',probability=True)\n",
    "svm_model_final.fit(final_X, Y_train)\n",
    "svm_model_final.score(final_X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 2, 2)              6         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 2, 2)             8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 1, 2)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 31\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_basic = Sequential() \n",
    "\n",
    "\n",
    "model_basic.add(Conv1D(2, kernel_size=2, input_shape = (3, 1), activation = 'relu'))\n",
    "# model_basic.add(Conv1D(2, kernel_siz=2, activation = 'relu'))\n",
    "model_basic.add(BatchNormalization())\n",
    "model_basic.add(MaxPooling1D(pool_size = (2)))\n",
    "\n",
    "\n",
    "model_basic.add(Flatten())\n",
    "model_basic.add(Dropout(0.5))\n",
    "# model_basic.add(Dense(units=100, activation = 'relu'))\n",
    "model_basic.add(Dense(units=5, activation = 'relu'))\n",
    "model_basic.add(Dense(units=1, activation = 'relu'))\n",
    "\n",
    "model_basic.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_basic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 1.3462 - accuracy: 0.6206 - val_loss: 2.7856 - val_accuracy: 0.5963\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 1.2294 - accuracy: 0.6742 - val_loss: 2.8114 - val_accuracy: 0.5963\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 961us/step - loss: 1.1635 - accuracy: 0.6774 - val_loss: 2.7990 - val_accuracy: 0.5963\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.6590 - val_loss: 2.7499 - val_accuracy: 0.5963\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 996us/step - loss: 1.0550 - accuracy: 0.6678 - val_loss: 2.7932 - val_accuracy: 0.5963\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 987us/step - loss: 0.9779 - accuracy: 0.6826 - val_loss: 2.7657 - val_accuracy: 0.5963\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0370 - accuracy: 0.6720 - val_loss: 2.7714 - val_accuracy: 0.5963\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 1.0210 - accuracy: 0.6894 - val_loss: 2.7785 - val_accuracy: 0.5963\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9506 - accuracy: 0.6824 - val_loss: 2.7869 - val_accuracy: 0.5963\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9520 - accuracy: 0.6824 - val_loss: 2.8542 - val_accuracy: 0.5963\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.9851 - accuracy: 0.6740 - val_loss: 2.8283 - val_accuracy: 0.5963\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9993 - accuracy: 0.6866 - val_loss: 2.8344 - val_accuracy: 0.5963\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 994us/step - loss: 1.0098 - accuracy: 0.6910 - val_loss: 2.9447 - val_accuracy: 0.5963\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.9883 - accuracy: 0.6920 - val_loss: 3.0062 - val_accuracy: 0.5963\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9659 - accuracy: 0.6838 - val_loss: 2.9654 - val_accuracy: 0.5963\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9299 - accuracy: 0.6914 - val_loss: 1.2724 - val_accuracy: 0.5963\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9630 - accuracy: 0.6930 - val_loss: 2.9143 - val_accuracy: 0.5963\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9656 - accuracy: 0.6862 - val_loss: 2.6594 - val_accuracy: 0.5963\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 987us/step - loss: 0.9460 - accuracy: 0.6880 - val_loss: 1.5166 - val_accuracy: 0.5963\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.9423 - accuracy: 0.6842 - val_loss: 2.5782 - val_accuracy: 0.5963\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.6536 - accuracy: 0.6890 - val_loss: 2.5003 - val_accuracy: 0.5963\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 987us/step - loss: 0.5055 - accuracy: 0.6870 - val_loss: 2.5286 - val_accuracy: 0.5963\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.6788 - val_loss: 2.5501 - val_accuracy: 0.5963\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.6870 - val_loss: 2.5286 - val_accuracy: 0.5963\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.6736 - val_loss: 2.5369 - val_accuracy: 0.5963\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.6862 - val_loss: 2.5551 - val_accuracy: 0.5963\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.6908 - val_loss: 2.5312 - val_accuracy: 0.5963\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.6972 - val_loss: 2.5519 - val_accuracy: 0.5963\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.6830 - val_loss: 2.5698 - val_accuracy: 0.5963\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.6802 - val_loss: 2.6193 - val_accuracy: 0.5963\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.6868 - val_loss: 2.5274 - val_accuracy: 0.5963\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.5101 - accuracy: 0.6852 - val_loss: 2.5627 - val_accuracy: 0.5963\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.6834 - val_loss: 2.5530 - val_accuracy: 0.5963\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.6794 - val_loss: 2.5391 - val_accuracy: 0.5963\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.6850 - val_loss: 2.5969 - val_accuracy: 0.5963\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.6818 - val_loss: 2.5664 - val_accuracy: 0.5963\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.5048 - accuracy: 0.6844 - val_loss: 2.5860 - val_accuracy: 0.5963\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.5043 - accuracy: 0.6926 - val_loss: 2.6201 - val_accuracy: 0.5963\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.6778 - val_loss: 2.5482 - val_accuracy: 0.5963\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.6888 - val_loss: 2.5968 - val_accuracy: 0.5963\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 996us/step - loss: 0.5098 - accuracy: 0.6834 - val_loss: 2.5785 - val_accuracy: 0.5963\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.6888 - val_loss: 2.5646 - val_accuracy: 0.5963\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.6826 - val_loss: 2.5562 - val_accuracy: 0.5963\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.5057 - accuracy: 0.6940 - val_loss: 2.5444 - val_accuracy: 0.5963\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.6916 - val_loss: 2.6900 - val_accuracy: 0.5963\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.6944 - val_loss: 2.5856 - val_accuracy: 0.5963\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.6884 - val_loss: 2.5766 - val_accuracy: 0.5963\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.6802 - val_loss: 2.5629 - val_accuracy: 0.5963\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.6886 - val_loss: 2.5680 - val_accuracy: 0.5963\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 992us/step - loss: 0.5184 - accuracy: 0.6812 - val_loss: 2.5646 - val_accuracy: 0.5963\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.6972 - val_loss: 2.5184 - val_accuracy: 0.5963\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 971us/step - loss: 0.5014 - accuracy: 0.6970 - val_loss: 2.5744 - val_accuracy: 0.5963\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.6766 - val_loss: 2.6016 - val_accuracy: 0.5963\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.6848 - val_loss: 2.5634 - val_accuracy: 0.5963\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.6826 - val_loss: 2.5479 - val_accuracy: 0.5963\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.5178 - accuracy: 0.6824 - val_loss: 2.6243 - val_accuracy: 0.5963\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.6770 - val_loss: 2.5247 - val_accuracy: 0.5963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.6896 - val_loss: 2.5238 - val_accuracy: 0.5963\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.5107 - accuracy: 0.6890 - val_loss: 2.5663 - val_accuracy: 0.5963\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.6912 - val_loss: 2.5957 - val_accuracy: 0.5963\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.5004 - accuracy: 0.6868 - val_loss: 2.5838 - val_accuracy: 0.5963\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.5094 - accuracy: 0.6898 - val_loss: 2.5779 - val_accuracy: 0.5963\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.6822 - val_loss: 2.5710 - val_accuracy: 0.5963\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.6840 - val_loss: 2.6033 - val_accuracy: 0.5963\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.5054 - accuracy: 0.6812 - val_loss: 2.5821 - val_accuracy: 0.5963\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.6864 - val_loss: 2.5630 - val_accuracy: 0.5963\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.5052 - accuracy: 0.6884 - val_loss: 2.5439 - val_accuracy: 0.5963\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.6840 - val_loss: 2.5513 - val_accuracy: 0.5963\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.6908 - val_loss: 2.5345 - val_accuracy: 0.5963\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.5108 - accuracy: 0.6894 - val_loss: 2.5493 - val_accuracy: 0.5963\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.6898 - val_loss: 2.5741 - val_accuracy: 0.5963\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 957us/step - loss: 0.5118 - accuracy: 0.6868 - val_loss: 2.5351 - val_accuracy: 0.5963\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.6892 - val_loss: 2.5903 - val_accuracy: 0.5963\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.6936 - val_loss: 2.5765 - val_accuracy: 0.5963\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.5113 - accuracy: 0.6852 - val_loss: 2.5606 - val_accuracy: 0.5963\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 983us/step - loss: 0.5102 - accuracy: 0.6904 - val_loss: 2.5408 - val_accuracy: 0.5963\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.6766 - val_loss: 2.5647 - val_accuracy: 0.5963\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.5158 - accuracy: 0.6842 - val_loss: 2.5971 - val_accuracy: 0.5963\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.6910 - val_loss: 2.5600 - val_accuracy: 0.5963\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 987us/step - loss: 0.5140 - accuracy: 0.6782 - val_loss: 2.5417 - val_accuracy: 0.5963\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.6812 - val_loss: 2.5561 - val_accuracy: 0.5963\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.6882 - val_loss: 2.5992 - val_accuracy: 0.5963\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.5100 - accuracy: 0.6900 - val_loss: 2.5903 - val_accuracy: 0.5963\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.5034 - accuracy: 0.6882 - val_loss: 2.6183 - val_accuracy: 0.5963\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.6850 - val_loss: 2.6452 - val_accuracy: 0.5963\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.5059 - accuracy: 0.6880 - val_loss: 2.5709 - val_accuracy: 0.5963\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.6868 - val_loss: 2.5941 - val_accuracy: 0.5963\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.5225 - accuracy: 0.6742 - val_loss: 2.5882 - val_accuracy: 0.5963\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.5134 - accuracy: 0.6852 - val_loss: 2.5821 - val_accuracy: 0.5963\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.6810 - val_loss: 2.5847 - val_accuracy: 0.5963\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.5093 - accuracy: 0.6878 - val_loss: 2.5856 - val_accuracy: 0.5963\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.6712 - val_loss: 2.5703 - val_accuracy: 0.5963\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.6890 - val_loss: 2.6182 - val_accuracy: 0.5963\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.6834 - val_loss: 2.5321 - val_accuracy: 0.5963\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 985us/step - loss: 0.5055 - accuracy: 0.6904 - val_loss: 2.5563 - val_accuracy: 0.5963\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.5001 - accuracy: 0.6874 - val_loss: 2.5628 - val_accuracy: 0.5963\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.6768 - val_loss: 2.5850 - val_accuracy: 0.5963\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.6760 - val_loss: 2.6115 - val_accuracy: 0.5963\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.6878 - val_loss: 2.5517 - val_accuracy: 0.5963\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 982us/step - loss: 0.5132 - accuracy: 0.6846 - val_loss: 2.5071 - val_accuracy: 0.5963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2279eae62b0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basic.fit(final_X, Y_train, epochs= 100, batch_size=20, validation_data=(final_X_val, Y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trash\\assets\n"
     ]
    }
   ],
   "source": [
    "model_basic.save(\"trash\")\n",
    "# model_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model_basic.predict(final_X)\n",
    "predict=np.round(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4882"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
